{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    import queue\n",
    "except ImportError:\n",
    "    import Queue as queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../simulator/carla/PythonAPI/carla/dist/carla-0.9.6-py3.5-linux-x86_64.egg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_data_buffer(image):\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "    array = np.reshape(array, (image.height, image.width, 4))\n",
    "    array = array[:, :, :3]\n",
    "    return array\n",
    "\n",
    "class CarlaSyncMode(object):\n",
    "    \"\"\"\n",
    "    Context manager to synchronize output from different sensors. Synchronous\n",
    "    mode is enabled as long as we are inside this context\n",
    "\n",
    "        with CarlaSyncMode(world, sensors) as sync_mode:\n",
    "            while True:\n",
    "                data = sync_mode.tick(timeout=1.0)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, world, *sensors, **kwargs):\n",
    "        self.world = world\n",
    "        self.sensors = sensors\n",
    "        self.frame = None\n",
    "        self.delta_seconds = 1.0 / kwargs.get('fps', 20)\n",
    "        self._queues = []\n",
    "        self._settings = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        print(\"CarlaSyncMode.enter\")\n",
    "        self._settings = self.world.get_settings()\n",
    "        self.frame = self.world.apply_settings(carla.WorldSettings(\n",
    "            no_rendering_mode=False,\n",
    "            synchronous_mode=True,\n",
    "            fixed_delta_seconds=self.delta_seconds))\n",
    "\n",
    "        def make_queue(register_event):\n",
    "            q = queue.Queue()\n",
    "            register_event(q.put)\n",
    "            self._queues.append(q)\n",
    "\n",
    "        make_queue(self.world.on_tick)\n",
    "        for sensor in self.sensors:\n",
    "            make_queue(sensor.listen)\n",
    "        return self\n",
    "\n",
    "    def tick(self, timeout):\n",
    "        \n",
    "        self.frame = self.world.tick()\n",
    "        data = [self._retrieve_data(q, timeout) for q in self._queues]\n",
    "        assert all(x.frame == self.frame for x in data)\n",
    "        return data\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        print(\"CarlaSyncMode.exit\")\n",
    "        self.world.apply_settings(self._settings)\n",
    "\n",
    "    def _retrieve_data(self, sensor_queue, timeout):\n",
    "        while True:\n",
    "            data = sensor_queue.get(timeout=timeout)\n",
    "            if data.frame == self.frame:\n",
    "                return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientSideBoundingBoxes(object):\n",
    "    \"\"\"\n",
    "    This is a module responsible for creating 3D bounding boxes and drawing them\n",
    "    client-side on pygame surface.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bounding_boxes(vehicles, camera):\n",
    "        \"\"\"\n",
    "        Creates 3D bounding boxes based on carla vehicle list and camera.\n",
    "        \"\"\"\n",
    "\n",
    "        bounding_boxes = [ClientSideBoundingBoxes.get_bounding_box(vehicle, camera) for vehicle in vehicles]\n",
    "        # filter objects behind camera\n",
    "        bounding_boxes = [bb for bb in bounding_boxes if all(bb[:, 2] > 0)]\n",
    "        return bounding_boxes\n",
    "\n",
    "    @staticmethod\n",
    "    def draw_bounding_boxes(image, bounding_boxes):\n",
    "        \"\"\"\n",
    "        Draws bounding boxes on pygame display.\n",
    "        \"\"\"\n",
    "\n",
    "        for bbox in bounding_boxes:\n",
    "\n",
    "            points = [(int(bbox[i, 0]), int(bbox[i, 1])) for i in range(8)]\n",
    "            # draw lines\n",
    "            # base\n",
    "            image = cv2.line(image, points[0], points[1], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[1], points[2], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[2], points[3], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[3], points[0], (0, 255, 0), 1)\n",
    "            # top\n",
    "            image = cv2.line(image, points[4], points[5], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[5], points[6], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[6], points[7], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[7], points[4], (0, 255, 0), 1)\n",
    "            \n",
    "            # base-top\n",
    "            image = cv2.line(image, points[0], points[4], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[1], points[5], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[2], points[6], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[3], points[7], (0, 255, 0), 1)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bounding_box(vehicle, camera):\n",
    "        \"\"\"\n",
    "        Returns 3D bounding box for a vehicle based on camera view.\n",
    "        \"\"\"\n",
    "\n",
    "        bb_cords = ClientSideBoundingBoxes._create_bb_points(vehicle)\n",
    "        cords_x_y_z = ClientSideBoundingBoxes._vehicle_to_sensor(bb_cords, vehicle, camera)[:3, :]\n",
    "        cords_y_minus_z_x = np.concatenate([cords_x_y_z[1, :], -cords_x_y_z[2, :], cords_x_y_z[0, :]])\n",
    "        bbox = np.transpose(np.dot(camera.calibration, cords_y_minus_z_x))\n",
    "        camera_bbox = np.concatenate([bbox[:, 0] / bbox[:, 2], bbox[:, 1] / bbox[:, 2], bbox[:, 2]], axis=1)\n",
    "        return camera_bbox\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_bb_points(vehicle):\n",
    "        \"\"\"\n",
    "        Returns 3D bounding box for a vehicle.\n",
    "        \"\"\"\n",
    "\n",
    "        cords = np.zeros((8, 4))\n",
    "        extent = vehicle.bounding_box.extent\n",
    "        cords[0, :] = np.array([extent.x, extent.y, -extent.z, 1])\n",
    "        cords[1, :] = np.array([-extent.x, extent.y, -extent.z, 1])\n",
    "        cords[2, :] = np.array([-extent.x, -extent.y, -extent.z, 1])\n",
    "        cords[3, :] = np.array([extent.x, -extent.y, -extent.z, 1])\n",
    "        cords[4, :] = np.array([extent.x, extent.y, extent.z, 1])\n",
    "        cords[5, :] = np.array([-extent.x, extent.y, extent.z, 1])\n",
    "        cords[6, :] = np.array([-extent.x, -extent.y, extent.z, 1])\n",
    "        cords[7, :] = np.array([extent.x, -extent.y, extent.z, 1])\n",
    "        return cords\n",
    "\n",
    "    @staticmethod\n",
    "    def _vehicle_to_sensor(cords, vehicle, sensor):\n",
    "        \"\"\"\n",
    "        Transforms coordinates of a vehicle bounding box to sensor.\n",
    "        \"\"\"\n",
    "\n",
    "        world_cord = ClientSideBoundingBoxes._vehicle_to_world(cords, vehicle)\n",
    "        sensor_cord = ClientSideBoundingBoxes._world_to_sensor(world_cord, sensor)\n",
    "        return sensor_cord\n",
    "\n",
    "    @staticmethod\n",
    "    def _vehicle_to_world(cords, vehicle):\n",
    "        \"\"\"\n",
    "        Transforms coordinates of a vehicle bounding box to world.\n",
    "        \"\"\"\n",
    "\n",
    "        bb_transform = carla.Transform(vehicle.bounding_box.location)\n",
    "        bb_vehicle_matrix = ClientSideBoundingBoxes.get_matrix(bb_transform)\n",
    "        vehicle_world_matrix = ClientSideBoundingBoxes.get_matrix(vehicle.get_transform())\n",
    "        bb_world_matrix = np.dot(vehicle_world_matrix, bb_vehicle_matrix)\n",
    "        world_cords = np.dot(bb_world_matrix, np.transpose(cords))\n",
    "        return world_cords\n",
    "\n",
    "    @staticmethod\n",
    "    def _world_to_sensor(cords, sensor):\n",
    "        \"\"\"\n",
    "        Transforms world coordinates to sensor.\n",
    "        \"\"\"\n",
    "\n",
    "        sensor_world_matrix = ClientSideBoundingBoxes.get_matrix(sensor.get_transform())\n",
    "        world_sensor_matrix = np.linalg.inv(sensor_world_matrix)\n",
    "        sensor_cords = np.dot(world_sensor_matrix, cords)\n",
    "        return sensor_cords\n",
    "\n",
    "    @staticmethod\n",
    "    def get_matrix(transform):\n",
    "        \"\"\"\n",
    "        Creates matrix from carla transform.\n",
    "        \"\"\"\n",
    "\n",
    "        rotation = transform.rotation\n",
    "        location = transform.location\n",
    "        c_y = np.cos(np.radians(rotation.yaw))\n",
    "        s_y = np.sin(np.radians(rotation.yaw))\n",
    "        c_r = np.cos(np.radians(rotation.roll))\n",
    "        s_r = np.sin(np.radians(rotation.roll))\n",
    "        c_p = np.cos(np.radians(rotation.pitch))\n",
    "        s_p = np.sin(np.radians(rotation.pitch))\n",
    "        matrix = np.matrix(np.identity(4))\n",
    "        matrix[0, 3] = location.x\n",
    "        matrix[1, 3] = location.y\n",
    "        matrix[2, 3] = location.z\n",
    "        matrix[0, 0] = c_p * c_y\n",
    "        matrix[0, 1] = c_y * s_p * s_r - s_y * c_r\n",
    "        matrix[0, 2] = -c_y * s_p * c_r - s_y * s_r\n",
    "        matrix[1, 0] = s_y * c_p\n",
    "        matrix[1, 1] = s_y * s_p * s_r + c_y * c_r\n",
    "        matrix[1, 2] = -s_y * s_p * c_r + c_y * s_r\n",
    "        matrix[2, 0] = s_p\n",
    "        matrix[2, 1] = -c_p * s_r\n",
    "        matrix[2, 2] = c_p * c_r\n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStorageWriter:\n",
    "\n",
    "    def __init__(self, file_path, sensor_names=[\"lidar1\", \"camera_rgb1\", \"camera_semseg1\", \"gnss\", \"bouding_boxes\"]):\n",
    "        self.h5 = h5py.File(file_path, 'w')\n",
    "        self.groups = dict()\n",
    "        for group_name in sensor_names:\n",
    "            self.groups[group_name] = self.h5.create_group(group_name)\n",
    "    \n",
    "    def write_lidar(self, sensor_name, index, lidar_measurement):\n",
    "        x, y, z = list(), list(), list()\n",
    "        for location in lidar_measurement:\n",
    "            x.append(location.x)\n",
    "            y.append(location.y)\n",
    "            z.append(location.z)\n",
    "        value = np.hstack([np.array(x).reshape((-1, 1)), np.array(y).reshape((-1, 1)), np.array(z).reshape((-1, 1))])\n",
    "        self.write_matrix(sensor_name, index, value)\n",
    "    \n",
    "    def write_gnss(self, sensor_name, index, gnss_data):\n",
    "        x, y, z = list(), list(), list()\n",
    "        x.append(gnss_data.latitude)\n",
    "        y.append(gnss_data.longitude)\n",
    "        z.append(gnss_data.altitude)\n",
    "        value = np.hstack([np.array(x).reshape((-1, 1)), np.array(y).reshape((-1, 1)), np.array(z).reshape((-1, 1))])\n",
    "        self.write_matrix(sensor_name, index, value)\n",
    "        \n",
    "    def write_image(self, sensor_name, index, image):\n",
    "        self.write_matrix(sensor_name, index, image)\n",
    "\n",
    "    def write_matrix(self, sensor_name, index, value):\n",
    "        self.groups[sensor_name].create_dataset(str(index), data=value, maxshape=value.shape, chunks=True)\n",
    "\n",
    "    def close(self):\n",
    "        self.h5.close()\n",
    "        self.h5 = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = client.get_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = world.get_weather()\n",
    "weather.cloudyness = 0\n",
    "weather.precipitation = 0\n",
    "weather.precipitation_deposits = 0\n",
    "weather.wind_intensity = 0\n",
    "weather.sun_azimuth_angle = 30\n",
    "weather.sun_altitude_angle = 100\n",
    "world.set_weather(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "blueprint_library = world.get_blueprint_library()\n",
    "actor_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add EGO Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = random.choice(blueprint_library.filter('vehicle.tesla.*'))\n",
    "transform = carla.Transform(carla.Location(x=-88.5, y=-160, z=0.8), carla.Rotation(pitch=0.000000, yaw=90.0, roll=0.000000))\n",
    "ego_vehicle = world.spawn_actor(bp, transform)\n",
    "actor_list.append(ego_vehicle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Other Opponents (Vehicles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = random.choice(blueprint_library.filter('vehicle.tesla.*'))\n",
    "transform = carla.Transform(carla.Location(x=-88.5, y=-120, z=0.8), carla.Rotation(pitch=0.000000, yaw=90.0, roll=0.000000))\n",
    "op_vehicle1 = world.spawn_actor(bp, transform)\n",
    "actor_list.append(op_vehicle1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW_WIDTH = 1024//2\n",
    "VIEW_HEIGHT = 768//2\n",
    "VIEW_FOV = 90\n",
    "\n",
    "camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', str(VIEW_WIDTH))\n",
    "camera_bp.set_attribute('image_size_y', str(VIEW_HEIGHT))\n",
    "camera_bp.set_attribute('fov', str(VIEW_FOV))\n",
    "\n",
    "camera_rgb = world.spawn_actor(\n",
    "    camera_bp,\n",
    "    carla.Transform(carla.Location(x=-5.5, z=2.8), carla.Rotation(pitch=-25)),\n",
    "    attach_to=ego_vehicle)\n",
    "\n",
    "calibration = np.identity(3)\n",
    "calibration[0, 2] = VIEW_WIDTH / 2.0\n",
    "calibration[1, 2] = VIEW_HEIGHT / 2.0\n",
    "calibration[0, 0] = calibration[1, 1] = VIEW_WIDTH / (2.0 * np.tan(VIEW_FOV * np.pi / 360.0))\n",
    "\n",
    "camera_rgb.calibration = calibration\n",
    "\n",
    "actor_list.append(camera_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_semseg_bp = blueprint_library.find('sensor.camera.semantic_segmentation')\n",
    "camera_semseg_bp.set_attribute('image_size_x', str(VIEW_WIDTH))\n",
    "camera_semseg_bp.set_attribute('image_size_y', str(VIEW_HEIGHT))\n",
    "camera_semseg_bp.set_attribute('fov', str(VIEW_FOV))\n",
    "\n",
    "camera_semseg = world.spawn_actor(\n",
    "    camera_semseg_bp,\n",
    "    carla.Transform(carla.Location(x=-5.5, z=2.8), carla.Rotation(pitch=-25)),\n",
    "    attach_to=ego_vehicle)\n",
    "\n",
    "camera_semseg.calibration = calibration\n",
    "\n",
    "actor_list.append(camera_semseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_depth_bp = blueprint_library.find('sensor.camera.depth')\n",
    "camera_depth_bp.set_attribute('image_size_x', str(VIEW_WIDTH))\n",
    "camera_depth_bp.set_attribute('image_size_y', str(VIEW_HEIGHT))\n",
    "camera_depth_bp.set_attribute('fov', str(VIEW_FOV))\n",
    "\n",
    "camera_depth = world.spawn_actor(\n",
    "    camera_depth_bp,\n",
    "    carla.Transform(carla.Location(x=-5.5, z=2.8), carla.Rotation(pitch=-25)),\n",
    "    attach_to=ego_vehicle)\n",
    "\n",
    "camera_depth.calibration = calibration\n",
    "\n",
    "actor_list.append(camera_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_bp = blueprint_library.find('sensor.lidar.ray_cast')\n",
    "\n",
    "lidar = world.spawn_actor(\n",
    "    lidar_bp,\n",
    "    carla.Transform(carla.Location(x=1.5, z=2.4)),\n",
    "    attach_to=ego_vehicle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnss_bp = blueprint_library.find('sensor.other.gnss')\n",
    "gnss_transform = carla.Transform(carla.Location(x=1.5, z=2.4))\n",
    "gnss = world.spawn_actor(\n",
    "    gnss_bp,\n",
    "    gnss_transform,\n",
    "    attach_to=ego_vehicle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = world.get_actors().filter('vehicle.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to truncate a file which is already open)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-bfb581bc98d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataStorageWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../dataset/data3.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"lidar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"camera\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gnss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"semantic\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mCarlaSyncMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_semseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlidar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgnss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msync_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mego_vehicle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_velocity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVector3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mop_vehicle1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_velocity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVector3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-d0fc872932bb>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_path, sensor_names)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lidar1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"camera_rgb1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"camera_semseg1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gnss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bouding_boxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msensor_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to truncate a file which is already open)"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ds = DataStorageWriter(\"../../dataset/data3.h5\", [\"lidar\", \"camera\", \"gnss\", \"semantic\"])        \n",
    "    with CarlaSyncMode(world, camera_rgb, camera_semseg, lidar, gnss, fps=30) as sync_mode:\n",
    "        ego_vehicle.set_velocity(carla.Vector3D(0.0, 10.3, 0))\n",
    "        op_vehicle1.set_velocity(carla.Vector3D(0.0, 5.3, 0))\n",
    "        for idx in range(30*10):\n",
    "            snapshot, image_rgb, image_seg, lidar_pcl, gnss_data = sync_mode.tick(timeout=2.0)\n",
    "            image_seg.convert(carla.ColorConverter.CityScapesPalette)\n",
    "            np_image = compute_data_buffer(image_rgb)\n",
    "\n",
    "            bounding_boxes = ClientSideBoundingBoxes.get_bounding_boxes(vehicles, camera_rgb)\n",
    "            np_image2 = ClientSideBoundingBoxes.draw_bounding_boxes(np_image, bounding_boxes)\n",
    "            frame = snapshot.frame\n",
    "            ts = int(snapshot.timestamp.elapsed_seconds * 1e6)\n",
    "            \n",
    "            ds.write_lidar(\"lidar\", ts, lidar_pcl)\n",
    "            ds.write_image(\"camera\", ts,  compute_data_buffer(image_rgb))\n",
    "            ds.write_image(\"semantic\", ts,  compute_data_buffer(image_seg))\n",
    "            ds.write_gnss(\"gnss\", ts, gnss_data)\n",
    "            \n",
    "            cv2.imshow(\"img\", np_image2)\n",
    "            \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "            if ego_vehicle.get_location().y > 140:\n",
    "                break\n",
    "finally:\n",
    "    for actor in actor_list:\n",
    "        actor.destroy()\n",
    "    actor_list = []\n",
    "    cv2.destroyAllWindows()\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
