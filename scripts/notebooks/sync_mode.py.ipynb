{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "try:\n",
    "    import queue\n",
    "except ImportError:\n",
    "    import Queue as queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../simulator/carla/PythonAPI/carla/dist/carla-0.9.6-py3.5-linux-x86_64.egg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_data_buffer(image):\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "    array = np.reshape(array, (image.height, image.width, 4))\n",
    "    array = array[:, :, :3]\n",
    "    return array\n",
    "\n",
    "class CarlaSyncMode(object):\n",
    "    \"\"\"\n",
    "    Context manager to synchronize output from different sensors. Synchronous\n",
    "    mode is enabled as long as we are inside this context\n",
    "\n",
    "        with CarlaSyncMode(world, sensors) as sync_mode:\n",
    "            while True:\n",
    "                data = sync_mode.tick(timeout=1.0)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, world, *sensors, **kwargs):\n",
    "        self.world = world\n",
    "        self.sensors = sensors\n",
    "        self.frame = None\n",
    "        self.delta_seconds = 1.0 / kwargs.get('fps', 20)\n",
    "        self._queues = []\n",
    "        self._settings = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        print(\"CarlaSyncMode.enter\")\n",
    "        self._settings = self.world.get_settings()\n",
    "        self.frame = self.world.apply_settings(carla.WorldSettings(\n",
    "            no_rendering_mode=False,\n",
    "            synchronous_mode=True,\n",
    "            fixed_delta_seconds=self.delta_seconds))\n",
    "\n",
    "        def make_queue(register_event):\n",
    "            q = queue.Queue()\n",
    "            register_event(q.put)\n",
    "            self._queues.append(q)\n",
    "\n",
    "        make_queue(self.world.on_tick)\n",
    "        for sensor in self.sensors:\n",
    "            make_queue(sensor.listen)\n",
    "        return self\n",
    "\n",
    "    def tick(self, timeout):\n",
    "        \n",
    "        self.frame = self.world.tick()\n",
    "        data = [self._retrieve_data(q, timeout) for q in self._queues]\n",
    "        assert all(x.frame == self.frame for x in data)\n",
    "        return data\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        print(\"CarlaSyncMode.exit\")\n",
    "        self.world.apply_settings(self._settings)\n",
    "\n",
    "    def _retrieve_data(self, sensor_queue, timeout):\n",
    "        while True:\n",
    "            data = sensor_queue.get(timeout=timeout)\n",
    "            if data.frame == self.frame:\n",
    "                return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientSideBoundingBoxes(object):\n",
    "    \"\"\"\n",
    "    This is a module responsible for creating 3D bounding boxes and drawing them\n",
    "    client-side on pygame surface.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bounding_boxes(vehicles, camera):\n",
    "        \"\"\"\n",
    "        Creates 3D bounding boxes based on carla vehicle list and camera.\n",
    "        \"\"\"\n",
    "\n",
    "        bounding_boxes = [ClientSideBoundingBoxes.get_bounding_box(vehicle, camera) for vehicle in vehicles]\n",
    "        # filter objects behind camera\n",
    "        bounding_boxes = [bb for bb in bounding_boxes if all(bb[:, 2] > 0)]\n",
    "        return bounding_boxes\n",
    "\n",
    "    @staticmethod\n",
    "    def draw_bounding_boxes(image, bounding_boxes):\n",
    "        \"\"\"\n",
    "        Draws bounding boxes on pygame display.\n",
    "        \"\"\"\n",
    "\n",
    "        for bbox in bounding_boxes:\n",
    "\n",
    "            points = [(int(bbox[i, 0]), int(bbox[i, 1])) for i in range(8)]\n",
    "            # draw lines\n",
    "            # base\n",
    "            image = cv2.line(image, points[0], points[1], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[1], points[2], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[2], points[3], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[3], points[0], (0, 255, 0), 1)\n",
    "            # top\n",
    "            image = cv2.line(image, points[4], points[5], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[5], points[6], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[6], points[7], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[7], points[4], (0, 255, 0), 1)\n",
    "            \n",
    "            # base-top\n",
    "            image = cv2.line(image, points[0], points[4], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[1], points[5], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[2], points[6], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[3], points[7], (0, 255, 0), 1)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bounding_box(vehicle, camera):\n",
    "        \"\"\"\n",
    "        Returns 3D bounding box for a vehicle based on camera view.\n",
    "        \"\"\"\n",
    "\n",
    "        bb_cords = ClientSideBoundingBoxes._create_bb_points(vehicle)\n",
    "        cords_x_y_z = ClientSideBoundingBoxes._vehicle_to_sensor(bb_cords, vehicle, camera)[:3, :]\n",
    "        cords_y_minus_z_x = np.concatenate([cords_x_y_z[1, :], -cords_x_y_z[2, :], cords_x_y_z[0, :]])\n",
    "        bbox = np.transpose(np.dot(camera.calibration, cords_y_minus_z_x))\n",
    "        camera_bbox = np.concatenate([bbox[:, 0] / bbox[:, 2], bbox[:, 1] / bbox[:, 2], bbox[:, 2]], axis=1)\n",
    "        return camera_bbox\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_bb_points(vehicle):\n",
    "        \"\"\"\n",
    "        Returns 3D bounding box for a vehicle.\n",
    "        \"\"\"\n",
    "\n",
    "        cords = np.zeros((8, 4))\n",
    "        extent = vehicle.bounding_box.extent\n",
    "        cords[0, :] = np.array([extent.x, extent.y, -extent.z, 1])\n",
    "        cords[1, :] = np.array([-extent.x, extent.y, -extent.z, 1])\n",
    "        cords[2, :] = np.array([-extent.x, -extent.y, -extent.z, 1])\n",
    "        cords[3, :] = np.array([extent.x, -extent.y, -extent.z, 1])\n",
    "        cords[4, :] = np.array([extent.x, extent.y, extent.z, 1])\n",
    "        cords[5, :] = np.array([-extent.x, extent.y, extent.z, 1])\n",
    "        cords[6, :] = np.array([-extent.x, -extent.y, extent.z, 1])\n",
    "        cords[7, :] = np.array([extent.x, -extent.y, extent.z, 1])\n",
    "        return cords\n",
    "\n",
    "    @staticmethod\n",
    "    def _vehicle_to_sensor(cords, vehicle, sensor):\n",
    "        \"\"\"\n",
    "        Transforms coordinates of a vehicle bounding box to sensor.\n",
    "        \"\"\"\n",
    "\n",
    "        world_cord = ClientSideBoundingBoxes._vehicle_to_world(cords, vehicle)\n",
    "        sensor_cord = ClientSideBoundingBoxes._world_to_sensor(world_cord, sensor)\n",
    "        return sensor_cord\n",
    "\n",
    "    @staticmethod\n",
    "    def _vehicle_to_world(cords, vehicle):\n",
    "        \"\"\"\n",
    "        Transforms coordinates of a vehicle bounding box to world.\n",
    "        \"\"\"\n",
    "\n",
    "        bb_transform = carla.Transform(vehicle.bounding_box.location)\n",
    "        bb_vehicle_matrix = ClientSideBoundingBoxes.get_matrix(bb_transform)\n",
    "        vehicle_world_matrix = ClientSideBoundingBoxes.get_matrix(vehicle.get_transform())\n",
    "        bb_world_matrix = np.dot(vehicle_world_matrix, bb_vehicle_matrix)\n",
    "        world_cords = np.dot(bb_world_matrix, np.transpose(cords))\n",
    "        return world_cords\n",
    "\n",
    "    @staticmethod\n",
    "    def _world_to_sensor(cords, sensor):\n",
    "        \"\"\"\n",
    "        Transforms world coordinates to sensor.\n",
    "        \"\"\"\n",
    "\n",
    "        sensor_world_matrix = ClientSideBoundingBoxes.get_matrix(sensor.get_transform())\n",
    "        world_sensor_matrix = np.linalg.inv(sensor_world_matrix)\n",
    "        sensor_cords = np.dot(world_sensor_matrix, cords)\n",
    "        return sensor_cords\n",
    "\n",
    "    @staticmethod\n",
    "    def get_matrix(transform):\n",
    "        \"\"\"\n",
    "        Creates matrix from carla transform.\n",
    "        \"\"\"\n",
    "\n",
    "        rotation = transform.rotation\n",
    "        location = transform.location\n",
    "        c_y = np.cos(np.radians(rotation.yaw))\n",
    "        s_y = np.sin(np.radians(rotation.yaw))\n",
    "        c_r = np.cos(np.radians(rotation.roll))\n",
    "        s_r = np.sin(np.radians(rotation.roll))\n",
    "        c_p = np.cos(np.radians(rotation.pitch))\n",
    "        s_p = np.sin(np.radians(rotation.pitch))\n",
    "        matrix = np.matrix(np.identity(4))\n",
    "        matrix[0, 3] = location.x\n",
    "        matrix[1, 3] = location.y\n",
    "        matrix[2, 3] = location.z\n",
    "        matrix[0, 0] = c_p * c_y\n",
    "        matrix[0, 1] = c_y * s_p * s_r - s_y * c_r\n",
    "        matrix[0, 2] = -c_y * s_p * c_r - s_y * s_r\n",
    "        matrix[1, 0] = s_y * c_p\n",
    "        matrix[1, 1] = s_y * s_p * s_r + c_y * c_r\n",
    "        matrix[1, 2] = -s_y * s_p * c_r + c_y * s_r\n",
    "        matrix[2, 0] = s_p\n",
    "        matrix[2, 1] = -c_p * s_r\n",
    "        matrix[2, 2] = c_p * c_r\n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = client.get_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = world.get_weather()\n",
    "weather.cloudyness = 0\n",
    "weather.precipitation = 0\n",
    "weather.precipitation_deposits = 0\n",
    "weather.wind_intensity = 0\n",
    "weather.sun_azimuth_angle = 30\n",
    "weather.sun_altitude_angle = 100\n",
    "world.set_weather(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "blueprint_library = world.get_blueprint_library()\n",
    "actor_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add EGO Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = random.choice(blueprint_library.filter('vehicle.tesla.*'))\n",
    "transform = carla.Transform(carla.Location(x=-88.5, y=-160, z=0.8), carla.Rotation(pitch=0.000000, yaw=90.0, roll=0.000000))\n",
    "ego_vehicle = world.spawn_actor(bp, transform)\n",
    "actor_list.append(ego_vehicle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Other Opponents (Vehicles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = random.choice(blueprint_library.filter('vehicle.tesla.*'))\n",
    "transform = carla.Transform(carla.Location(x=-88.5, y=-120, z=0.8), carla.Rotation(pitch=0.000000, yaw=90.0, roll=0.000000))\n",
    "op_vehicle1 = world.spawn_actor(bp, transform)\n",
    "actor_list.append(op_vehicle1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW_WIDTH = 1024//2\n",
    "VIEW_HEIGHT = 768//2\n",
    "VIEW_FOV = 90\n",
    "\n",
    "camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', str(VIEW_WIDTH))\n",
    "camera_bp.set_attribute('image_size_y', str(VIEW_HEIGHT))\n",
    "camera_bp.set_attribute('fov', str(VIEW_FOV))\n",
    "\n",
    "camera_rgb = world.spawn_actor(\n",
    "    camera_bp,\n",
    "    carla.Transform(carla.Location(x=-5.5, z=2.8), carla.Rotation(pitch=-25)),\n",
    "    attach_to=ego_vehicle)\n",
    "\n",
    "calibration = np.identity(3)\n",
    "calibration[0, 2] = VIEW_WIDTH / 2.0\n",
    "calibration[1, 2] = VIEW_HEIGHT / 2.0\n",
    "calibration[0, 0] = calibration[1, 1] = VIEW_WIDTH / (2.0 * np.tan(VIEW_FOV * np.pi / 360.0))\n",
    "\n",
    "camera_rgb.calibration = calibration\n",
    "\n",
    "actor_list.append(camera_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_semseg_bp = blueprint_library.find('sensor.camera.semantic_segmentation')\n",
    "camera_semseg_bp.set_attribute('image_size_x', str(VIEW_WIDTH))\n",
    "camera_semseg_bp.set_attribute('image_size_y', str(VIEW_HEIGHT))\n",
    "camera_semseg_bp.set_attribute('fov', str(VIEW_FOV))\n",
    "\n",
    "camera_semseg = world.spawn_actor(\n",
    "    camera_semseg_bp,\n",
    "    carla.Transform(carla.Location(x=-5.5, z=2.8), carla.Rotation(pitch=-25)),\n",
    "    attach_to=ego_vehicle)\n",
    "\n",
    "camera_semseg.calibration = calibration\n",
    "\n",
    "actor_list.append(camera_semseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_bp = blueprint_library.find('sensor.lidar.ray_cast')\n",
    "\n",
    "lidar = world.spawn_actor(\n",
    "    lidar_bp,\n",
    "    carla.Transform(carla.Location(x=1.5, z=2.4)),\n",
    "    attach_to=ego_vehicle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = world.get_actors().filter('vehicle.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarlaSyncMode.enter\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with CarlaSyncMode(world, camera_rgb, camera_semseg, lidar, fps=30) as sync_mode:\n",
    "        ego_vehicle.set_velocity(carla.Vector3D(0.0, 10.3, 0))\n",
    "        op_vehicle1.set_velocity(carla.Vector3D(0.0, 5.3, 0))\n",
    "        for idx in range(30*10):\n",
    "            snapshot, image_rgb, image_seg, lidar_pcl = sync_mode.tick(timeout=2.0)\n",
    "            image_seg.convert(carla.ColorConverter.CityScapesPalette)\n",
    "            np_image = compute_data_buffer(image_rgb)\n",
    "\n",
    "            bounding_boxes = ClientSideBoundingBoxes.get_bounding_boxes(vehicles, camera_rgb)\n",
    "            np_image = ClientSideBoundingBoxes.draw_bounding_boxes(np_image, bounding_boxes)\n",
    "\n",
    "            cv2.imshow(\"img\", np_image)\n",
    "            \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "            if ego_vehicle.get_location().y > 140:\n",
    "                break\n",
    "finally:\n",
    "    for actor in actor_list:\n",
    "        actor.destroy()\n",
    "    actor_list = []\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
