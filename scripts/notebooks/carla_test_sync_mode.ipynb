{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    import queue\n",
    "except ImportError:\n",
    "    import Queue as queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../simulator/carla/PythonAPI/carla/dist/carla-0.9.6-py3.5-linux-x86_64.egg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_data_buffer(image):\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "    array = np.reshape(array, (image.height, image.width, 4))\n",
    "    array = array[:, :, :3]\n",
    "    return array\n",
    "\n",
    "class CarlaSyncMode(object):\n",
    "    \"\"\"\n",
    "    Context manager to synchronize output from different sensors. Synchronous\n",
    "    mode is enabled as long as we are inside this context\n",
    "\n",
    "        with CarlaSyncMode(world, sensors) as sync_mode:\n",
    "            while True:\n",
    "                data = sync_mode.tick(timeout=1.0)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, world, sensors, **kwargs):\n",
    "        self.world = world\n",
    "        self.sensors = sensors\n",
    "        self.frame = None\n",
    "        self.delta_seconds = 1.0 / kwargs.get('fps', 20)\n",
    "        self._queues = []\n",
    "        self._settings = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        print(\"CarlaSyncMode.enter\")\n",
    "        self._settings = self.world.get_settings()\n",
    "        self.frame = self.world.apply_settings(carla.WorldSettings(\n",
    "            no_rendering_mode=False,\n",
    "            synchronous_mode=True,\n",
    "            fixed_delta_seconds=self.delta_seconds))\n",
    "\n",
    "        def make_queue(register_event):\n",
    "            q = queue.Queue()\n",
    "            register_event(q.put)\n",
    "            self._queues.append(q)\n",
    "\n",
    "        make_queue(self.world.on_tick)\n",
    "        for sensor in self.sensors:\n",
    "            make_queue(sensor.listen)\n",
    "        return self\n",
    "\n",
    "    def tick(self, timeout):\n",
    "        \n",
    "        self.frame = self.world.tick()\n",
    "        data = [self._retrieve_data(q, timeout) for q in self._queues]\n",
    "        assert all(x.frame == self.frame for x in data)\n",
    "        return data\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        print(\"CarlaSyncMode.exit\")\n",
    "        self.world.apply_settings(self._settings)\n",
    "\n",
    "    def _retrieve_data(self, sensor_queue, timeout):\n",
    "        while True:\n",
    "            data = sensor_queue.get(timeout=timeout)\n",
    "            if data.frame == self.frame:\n",
    "                return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientSideBoundingBoxes(object):\n",
    "    \"\"\"\n",
    "    This is a module responsible for creating 3D bounding boxes and drawing them\n",
    "    client-side on pygame surface.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bounding_boxes(vehicles, camera):\n",
    "        \"\"\"\n",
    "        Creates 3D bounding boxes based on carla vehicle list and camera.\n",
    "        \"\"\"\n",
    "\n",
    "        bounding_boxes = [ClientSideBoundingBoxes.get_bounding_box(vehicle, camera) for vehicle in vehicles]\n",
    "        # filter objects behind camera\n",
    "        bounding_boxes = [bb for bb in bounding_boxes if all(bb[:, 2] > 0)]\n",
    "        return bounding_boxes\n",
    "\n",
    "    @staticmethod\n",
    "    def draw_bounding_boxes(image, bounding_boxes):\n",
    "        \"\"\"\n",
    "        Draws bounding boxes on pygame display.\n",
    "        \"\"\"\n",
    "\n",
    "        for bbox in bounding_boxes:\n",
    "\n",
    "            points = [(int(bbox[i, 0]), int(bbox[i, 1])) for i in range(8)]\n",
    "            # draw lines\n",
    "            # base\n",
    "            image = cv2.line(image, points[0], points[1], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[1], points[2], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[2], points[3], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[3], points[0], (0, 255, 0), 1)\n",
    "            # top\n",
    "            image = cv2.line(image, points[4], points[5], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[5], points[6], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[6], points[7], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[7], points[4], (0, 255, 0), 1)\n",
    "            \n",
    "            # base-top\n",
    "            image = cv2.line(image, points[0], points[4], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[1], points[5], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[2], points[6], (0, 255, 0), 1)\n",
    "            image = cv2.line(image, points[3], points[7], (0, 255, 0), 1)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bounding_box(vehicle, camera):\n",
    "        \"\"\"\n",
    "        Returns 3D bounding box for a vehicle based on camera view.\n",
    "        \"\"\"\n",
    "\n",
    "        bb_cords = ClientSideBoundingBoxes._create_bb_points(vehicle)\n",
    "        cords_x_y_z = ClientSideBoundingBoxes._vehicle_to_sensor(bb_cords, vehicle, camera)[:3, :]\n",
    "        cords_y_minus_z_x = np.concatenate([cords_x_y_z[1, :], -cords_x_y_z[2, :], cords_x_y_z[0, :]])\n",
    "        bbox = np.transpose(np.dot(camera.calibration, cords_y_minus_z_x))\n",
    "        camera_bbox = np.concatenate([bbox[:, 0] / bbox[:, 2], bbox[:, 1] / bbox[:, 2], bbox[:, 2]], axis=1)\n",
    "        return camera_bbox\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_bb_points(vehicle):\n",
    "        \"\"\"\n",
    "        Returns 3D bounding box for a vehicle.\n",
    "        \"\"\"\n",
    "\n",
    "        cords = np.zeros((8, 4))\n",
    "        extent = vehicle.bounding_box.extent\n",
    "        cords[0, :] = np.array([extent.x, extent.y, -extent.z, 1])\n",
    "        cords[1, :] = np.array([-extent.x, extent.y, -extent.z, 1])\n",
    "        cords[2, :] = np.array([-extent.x, -extent.y, -extent.z, 1])\n",
    "        cords[3, :] = np.array([extent.x, -extent.y, -extent.z, 1])\n",
    "        cords[4, :] = np.array([extent.x, extent.y, extent.z, 1])\n",
    "        cords[5, :] = np.array([-extent.x, extent.y, extent.z, 1])\n",
    "        cords[6, :] = np.array([-extent.x, -extent.y, extent.z, 1])\n",
    "        cords[7, :] = np.array([extent.x, -extent.y, extent.z, 1])\n",
    "        return cords\n",
    "\n",
    "    @staticmethod\n",
    "    def _vehicle_to_sensor(cords, vehicle, sensor):\n",
    "        \"\"\"\n",
    "        Transforms coordinates of a vehicle bounding box to sensor.\n",
    "        \"\"\"\n",
    "\n",
    "        world_cord = ClientSideBoundingBoxes._vehicle_to_world(cords, vehicle)\n",
    "        sensor_cord = ClientSideBoundingBoxes._world_to_sensor(world_cord, sensor)\n",
    "        return sensor_cord\n",
    "\n",
    "    @staticmethod\n",
    "    def _vehicle_to_world(cords, vehicle):\n",
    "        \"\"\"\n",
    "        Transforms coordinates of a vehicle bounding box to world.\n",
    "        \"\"\"\n",
    "\n",
    "        bb_transform = carla.Transform(vehicle.bounding_box.location)\n",
    "        bb_vehicle_matrix = ClientSideBoundingBoxes.get_matrix(bb_transform)\n",
    "        vehicle_world_matrix = ClientSideBoundingBoxes.get_matrix(vehicle.get_transform())\n",
    "        bb_world_matrix = np.dot(vehicle_world_matrix, bb_vehicle_matrix)\n",
    "        world_cords = np.dot(bb_world_matrix, np.transpose(cords))\n",
    "        return world_cords\n",
    "\n",
    "    @staticmethod\n",
    "    def _world_to_sensor(cords, sensor):\n",
    "        \"\"\"\n",
    "        Transforms world coordinates to sensor.\n",
    "        \"\"\"\n",
    "\n",
    "        sensor_world_matrix = ClientSideBoundingBoxes.get_matrix(sensor.get_transform())\n",
    "        world_sensor_matrix = np.linalg.inv(sensor_world_matrix)\n",
    "        sensor_cords = np.dot(world_sensor_matrix, cords)\n",
    "        return sensor_cords\n",
    "\n",
    "    @staticmethod\n",
    "    def get_matrix(transform):\n",
    "        \"\"\"\n",
    "        Creates matrix from carla transform.\n",
    "        \"\"\"\n",
    "\n",
    "        rotation = transform.rotation\n",
    "        location = transform.location\n",
    "        c_y = np.cos(np.radians(rotation.yaw))\n",
    "        s_y = np.sin(np.radians(rotation.yaw))\n",
    "        c_r = np.cos(np.radians(rotation.roll))\n",
    "        s_r = np.sin(np.radians(rotation.roll))\n",
    "        c_p = np.cos(np.radians(rotation.pitch))\n",
    "        s_p = np.sin(np.radians(rotation.pitch))\n",
    "        matrix = np.matrix(np.identity(4))\n",
    "        matrix[0, 3] = location.x\n",
    "        matrix[1, 3] = location.y\n",
    "        matrix[2, 3] = location.z\n",
    "        matrix[0, 0] = c_p * c_y\n",
    "        matrix[0, 1] = c_y * s_p * s_r - s_y * c_r\n",
    "        matrix[0, 2] = -c_y * s_p * c_r - s_y * s_r\n",
    "        matrix[1, 0] = s_y * c_p\n",
    "        matrix[1, 1] = s_y * s_p * s_r + c_y * c_r\n",
    "        matrix[1, 2] = -s_y * s_p * c_r + c_y * s_r\n",
    "        matrix[2, 0] = s_p\n",
    "        matrix[2, 1] = -c_p * s_r\n",
    "        matrix[2, 2] = c_p * c_r\n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStorageWriter:\n",
    "\n",
    "    def __init__(self, file_path, sensor_names=[\"lidar1\", \"camera_rgb1\", \"camera_semseg1\", \"gnss\", \"bouding_boxes\"]):\n",
    "        self.h5 = h5py.File(file_path, 'w')\n",
    "        self.groups = dict()\n",
    "        for group_name in sensor_names:\n",
    "            self.groups[group_name] = self.h5.create_group(group_name)\n",
    "    \n",
    "    def write_lidar(self, sensor_name, index, lidar_measurement):\n",
    "        x, y, z = list(), list(), list()\n",
    "        for location in lidar_measurement:\n",
    "            x.append(location.x)\n",
    "            y.append(location.y)\n",
    "            z.append(location.z)\n",
    "        value = np.hstack([np.array(x).reshape((-1, 1)), np.array(y).reshape((-1, 1)), np.array(z).reshape((-1, 1))])\n",
    "        self.write_matrix(sensor_name, index, value)\n",
    "    \n",
    "    def write_gnss(self, sensor_name, index, gnss_data):\n",
    "        x, y, z = list(), list(), list()\n",
    "        x.append(gnss_data.latitude)\n",
    "        y.append(gnss_data.longitude)\n",
    "        z.append(gnss_data.altitude)\n",
    "        value = np.hstack([np.array(x).reshape((-1, 1)), np.array(y).reshape((-1, 1)), np.array(z).reshape((-1, 1))])\n",
    "        self.write_matrix(sensor_name, index, value)\n",
    "        \n",
    "    def write_image(self, sensor_name, index, image):\n",
    "        self.write_matrix(sensor_name, index, image)\n",
    "\n",
    "    def write_collision(self, sensor_name, index, collision_event):\n",
    "        self.write_matrix(sensor_name, index,\n",
    "                          np.array([collision_event.normal_impulse.x,\n",
    "                                    collision_event.normal_impulse.y,\n",
    "                                    collision_event.normal_impulse.z]).reshape((1, -1)))\n",
    "    \n",
    "    def write_matrix(self, sensor_name, index, value):\n",
    "        self.groups[sensor_name].create_dataset(str(index), data=value, maxshape=value.shape, chunks=True)\n",
    "    \n",
    "    def set_attributes(self, sensor_name, attrs):\n",
    "        for param in attrs:\n",
    "            self.groups[sensor_name].attrs[param] = attrs[param]\n",
    "    \n",
    "    def close(self):\n",
    "        self.h5.close()\n",
    "        self.h5 = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = client.get_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = world.get_weather()\n",
    "weather.cloudyness = 0\n",
    "weather.precipitation = 0\n",
    "weather.precipitation_deposits = 0\n",
    "weather.wind_intensity = 0\n",
    "weather.sun_azimuth_angle = 30\n",
    "weather.sun_altitude_angle = 100\n",
    "world.set_weather(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "blueprint_library = world.get_blueprint_library()\n",
    "actor_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add EGO Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = random.choice(blueprint_library.filter('vehicle.tesla.*'))\n",
    "transform = carla.Transform(carla.Location(x=-88.5, y=-160, z=0.8), carla.Rotation(pitch=0.000000, yaw=90.0, roll=0.000000))\n",
    "ego_vehicle = world.spawn_actor(bp, transform)\n",
    "actor_list.append(ego_vehicle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Other Opponents (Vehicles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = random.choice(blueprint_library.filter('vehicle.tesla.*'))\n",
    "transform = carla.Transform(carla.Location(x=-88.5, y=-120, z=0.8), carla.Rotation(pitch=0.000000, yaw=90.0, roll=0.000000))\n",
    "op_vehicle1 = world.spawn_actor(bp, transform)\n",
    "actor_list.append(op_vehicle1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_camera_sensors(world, vehicle, params):\n",
    "    \"\"\"\n",
    "        creates rgb, semantic and depth cameras\n",
    "        \n",
    "        parameters\n",
    "        ==========\n",
    "        \n",
    "            world: carla world object instance\n",
    "            vehicle: actor to attach the sensors\n",
    "            \n",
    "            params: dict with\n",
    "                - width: image camera width\n",
    "                - height: image camera height\n",
    "                - fov: camera field of view\n",
    "                - x, y, z, roll, pitch, yaw: position of the sensor\n",
    "        \n",
    "        return\n",
    "        ======\n",
    "            \n",
    "            [camera_rgb, camera_semseg, camera_depth] list with an rgb, semantic seg and depth camera object instance\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    transform = carla.Transform(carla.Location(x=params[\"x\"], y=params[\"y\"], z=params[\"z\"]),\n",
    "                                carla.Rotation(pitch=params[\"pitch\"], roll=params[\"roll\"], yaw=params[\"yaw\"]))\n",
    "    \n",
    "    calibration = np.identity(3)\n",
    "    calibration[0, 2] = params[\"width\"] / 2.0\n",
    "    calibration[1, 2] = params[\"height\"] / 2.0\n",
    "    calibration[0, 0] = calibration[1, 1] = params[\"width\"] / (2.0 * np.tan(params[\"fov\"] * np.pi / 360.0))\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    for sensor_name in ['sensor.camera.rgb', 'sensor.camera.semantic_segmentation', 'sensor.camera.depth']:\n",
    "        bp = blueprint_library.find(sensor_name)\n",
    "        bp.set_attribute('image_size_x', str(params[\"width\"]))\n",
    "        bp.set_attribute('image_size_y', str(params[\"height\"]))\n",
    "        bp.set_attribute('fov', str(params[\"fov\"]))\n",
    "        \n",
    "        cam = world.spawn_actor(bp, transform, attach_to=vehicle)\n",
    "        cam.calibration = calibration\n",
    "        output.append(cam)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lidar_sensor(world, vehicle, params):\n",
    "    \"\"\"\n",
    "        create a lidar sensor\n",
    "        \n",
    "        parameters\n",
    "        ==========\n",
    "            \n",
    "            world: carla world object instance\n",
    "            vehicle: actor to attach the sensors\n",
    "            \n",
    "            params: dict with\n",
    "                - channels: number of lines\n",
    "                - range: maximum range\n",
    "                - upper_fov: Angle in degrees of the upper most laser\n",
    "                - lower_fov: Angle in degrees of the lower most laser\n",
    "                - x, y, z, roll, pitch, yaw: position of the sensor\n",
    "            \n",
    "        return\n",
    "        ======\n",
    "            \n",
    "            lidar_sensor: carla lidar sensor\n",
    "            \n",
    "    \"\"\"\n",
    "    transform = carla.Transform(carla.Location(x=params[\"x\"], y=params[\"y\"], z=params[\"z\"]),\n",
    "                                carla.Rotation(pitch=params[\"pitch\"], roll=params[\"roll\"], yaw=params[\"yaw\"]))\n",
    "    \n",
    "    bp = blueprint_library.find('sensor.lidar.ray_cast')\n",
    "    bp.set_attribute('channels', str(params[\"channels\"]))\n",
    "    bp.set_attribute('range', str(params[\"range\"]))\n",
    "    bp.set_attribute('upper_fov', str(params[\"upper_fov\"]))\n",
    "    bp.set_attribute('lower_fov', str(params[\"lower_fov\"]))\n",
    "\n",
    "    return world.spawn_actor(bp, transform, attach_to=vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gnss_sensor(world, vehicle, params):\n",
    "    transform = carla.Transform(carla.Location(x=params[\"x\"], y=params[\"y\"], z=params[\"z\"]),\n",
    "                                carla.Rotation(pitch=params[\"pitch\"], roll=params[\"roll\"], yaw=params[\"yaw\"]))\n",
    "    gnss_bp = blueprint_library.find('sensor.other.gnss')\n",
    "    return world.spawn_actor(gnss_bp, transform, attach_to=vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_imu_sensor(world, vehicle, params):\n",
    "    transform = carla.Transform(carla.Location(x=params[\"x\"], y=params[\"y\"], z=params[\"z\"]),\n",
    "                                carla.Rotation(pitch=params[\"pitch\"], roll=params[\"roll\"], yaw=params[\"yaw\"]))\n",
    "    return world.spawn_actor(blueprint_library.find('sensor.other.imu'), transform, attach_to=vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sensors parameters\n",
    "\n",
    "camera1_parameters = {\"x\": -5.5, \"y\": 0, \"z\": 2.8, \"roll\": 0, \"pitch\": -25, \"yaw\": 0,\n",
    "                      \"width\": 1024, \"height\": 768, \"fov\": 90,\n",
    "                      \"sensor_label\": \"camera1\",\n",
    "                      \"sensor_type\": \"camera\"}\n",
    "\n",
    "camera2_parameters = {\"x\": -5.5, \"y\": 0, \"z\": 2.8, \"roll\": 0, \"pitch\": -25, \"yaw\": 45,\n",
    "                      \"width\": 1024, \"height\": 768, \"fov\": 90,\n",
    "                      \"sensor_label\": \"camera2\",\n",
    "                      \"sensor_type\": \"camera\"}\n",
    "\n",
    "camera3_parameters = {\"x\": -5.5, \"y\": 0, \"z\": 2.8, \"roll\": 0, \"pitch\": -25, \"yaw\": 90,\n",
    "                      \"width\": 1024, \"height\": 768, \"fov\": 90,\n",
    "                      \"sensor_label\": \"camera3\",\n",
    "                      \"sensor_type\": \"camera\"}\n",
    "\n",
    "camera4_parameters = {\"x\": -5.5, \"y\": 0, \"z\": 2.8, \"roll\": 0, \"pitch\": -25, \"yaw\": 135,\n",
    "                      \"width\": 1024, \"height\": 768, \"fov\": 90,\n",
    "                      \"sensor_label\": \"camera4\",\n",
    "                      \"sensor_type\": \"camera\"}\n",
    "\n",
    "camera5_parameters = {\"x\": -5.5, \"y\": 0, \"z\": 2.8, \"roll\": 0, \"pitch\": -25, \"yaw\": 180,\n",
    "                      \"width\": 1024, \"height\": 768, \"fov\": 90,\n",
    "                      \"sensor_label\": \"camera5\",\n",
    "                      \"sensor_type\": \"camera\"}\n",
    "\n",
    "camera6_parameters = {\"x\": -5.5, \"y\": 0, \"z\": 2.8, \"roll\": 0, \"pitch\": -25, \"yaw\": 225,\n",
    "                      \"width\": 1024, \"height\": 768, \"fov\": 90,\n",
    "                      \"sensor_label\": \"camera6\",\n",
    "                      \"sensor_type\": \"camera\"}\n",
    "\n",
    "camera7_parameters = {\"x\": -5.5, \"y\": 0, \"z\": 2.8, \"roll\": 0, \"pitch\": -25, \"yaw\": 270,\n",
    "                      \"width\": 1024, \"height\": 768, \"fov\": 90,\n",
    "                      \"sensor_label\": \"camera7\",\n",
    "                      \"sensor_type\": \"camera\"}\n",
    "\n",
    "camera8_parameters = {\"x\": -5.5, \"y\": 0, \"z\": 2.8, \"roll\": 0, \"pitch\": -25, \"yaw\": 315,\n",
    "                      \"width\": 1024, \"height\": 768, \"fov\": 90,\n",
    "                      \"sensor_label\": \"camera8\",\n",
    "                      \"sensor_type\": \"camera\"}\n",
    "\n",
    "lidar1_parameters = {\"x\": 1.5, \"y\": 0, \"z\": 2.4, \"roll\": 0, \"pitch\": 0, \"yaw\": 0,\n",
    "                     \"channels\": 32, \"range\": 100, \"lower_fov\": -30, \"upper_fov\": 15,\n",
    "                     \"sensor_label\": \"lidar\",\n",
    "                     \"sensor_type\": \"camera\"}\n",
    "\n",
    "gnss_parameters = {\"x\": 1.5, \"y\": 0, \"z\": 2.4, \"roll\": 0, \"pitch\": 0, \"yaw\": 0,\n",
    "                   \"sensor_label\": \"gnss\",\n",
    "                    \"sensor_type\": \"gnss\"}\n",
    "\n",
    "collision_parameters = {\"sensor_label\": \"collision\", \"sensor_type\": \"collision\"}\n",
    "\n",
    "\n",
    "sensor_labels = ['camera1','camera1','camera1',\n",
    "                 'camera2','camera2','camera2',\n",
    "                 'camera3','camera3','camera3',\n",
    "                 'camera4','camera4','camera4',\n",
    "                 'camera5','camera5','camera5',\n",
    "                 'camera6','camera6','camera6',\n",
    "                 'camera7','camera7','camera7',\n",
    "                 'camera8','camera8','camera8',\n",
    "                 'camera8',\n",
    "                 'gnss',\n",
    "                 'collision']\n",
    "\n",
    "\n",
    "# imu_parameters = {\"x\": 1.5, \"y\": 0, \"z\": 2.4, \"roll\": 0, \"pitch\": 0, \"yaw\": 0,\n",
    "#                   \"sensor_label\": \"imu\",\n",
    "#                   \"sensor_type\": \"imu\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['camera1',\n",
       " 'camera2',\n",
       " 'camera3',\n",
       " 'camera4',\n",
       " 'camera5',\n",
       " 'camera6',\n",
       " 'camera7',\n",
       " 'camera8',\n",
       " 'camera8',\n",
       " 'gnss',\n",
       " 'collision']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_actor_list = []\n",
    "sensors_parameters = []\n",
    "\n",
    "# create cameras\n",
    "for camera_parameter in [camera1_parameters, camera2_parameters, camera3_parameters, camera4_parameters, camera5_parameters, camera6_parameters, camera7_parameters, camera8_parameters]:\n",
    "    sensor_actor_list += create_camera_sensors(world, ego_vehicle, camera_parameter)\n",
    "    sensors_parameters.append(camera_parameter)\n",
    "    \n",
    "# create lidars\n",
    "for lidar_parameter in [lidar1_parameters]:\n",
    "    sensor_actor_list.append(create_lidar_sensor(world, ego_vehicle, lidar_parameter))\n",
    "    sensors_parameters.append(lidar_parameter)\n",
    "\n",
    "# create gnss\n",
    "for gnss_parameter in [gnss_parameters]:\n",
    "    sensor_actor_list.append(create_gnss_sensor(world, ego_vehicle, gnss_parameter))\n",
    "    sensors_parameters.append(gnss_parameter)\n",
    "\n",
    "# create collision sensor\n",
    "sensor_actor_list.append(world.spawn_actor(blueprint_library.find('sensor.other.collision'), carla.Transform(), attach_to=ego_vehicle))\n",
    "sensors_parameters.append({\"sensor_label\": \"collision\", \"sensor_type\": \"collision\"})\n",
    "\n",
    "# # create imu sensor\n",
    "# sensor_actor_list.append(create_imu_sensor(world, ego_vehicle, imu_parameters))\n",
    "# sensors_parameters.append(imu_parameters)\n",
    "\n",
    "\n",
    "# get name parameters list to create data storage file\n",
    "sensor_labels = [param[\"sensor_label\"] for param in sensors_parameters]\n",
    "sensor_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarlaSyncMode.enter\n",
      "CarlaSyncMode.exit\n"
     ]
    },
    {
     "ename": "Empty",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b456287d18a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m#snapshot, image_rgb, image_seg, lidar_pcl, gnss_data = sync_mode.tick(timeout=2.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msync_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mimage_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mimage_seg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a23813b8e239>\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a23813b8e239>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a23813b8e239>\u001b[0m in \u001b[0;36m_retrieve_data\u001b[0;34m(self, sensor_queue, timeout)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_retrieve_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msensor_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendtime\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \n",
    "    vehicles = world.get_actors().filter('vehicle.*')\n",
    "    \n",
    "    ds = DataStorageWriter(\"../../dataset/data3.h5\", [\"lidar\", \"camera\", \"gnss\", \"semantic\"])\n",
    "    \n",
    "    with CarlaSyncMode(world, sensor_actor_list, fps=30) as sync_mode:\n",
    "        \n",
    "        ego_vehicle.set_velocity(carla.Vector3D(0.0, 10.3, 0))\n",
    "        op_vehicle1.set_velocity(carla.Vector3D(0.0, 5.3, 0))\n",
    "        \n",
    "        for idx in range(30*10):\n",
    "            #snapshot, image_rgb, image_seg, lidar_pcl, gnss_data = sync_mode.tick(timeout=2.0)\n",
    "            \n",
    "            data = sync_mode.tick(timeout=10.0)\n",
    "            image_rgb = data[1]\n",
    "            image_seg = data[2]\n",
    "            snapshot = data[0]\n",
    "            \n",
    "            image_seg.convert(carla.ColorConverter.CityScapesPalette)\n",
    "            np_image = compute_data_buffer(image_rgb)\n",
    "\n",
    "            bounding_boxes = ClientSideBoundingBoxes.get_bounding_boxes(vehicles, camera_rgb)\n",
    "            np_image2 = ClientSideBoundingBoxes.draw_bounding_boxes(np_image, bounding_boxes)\n",
    "            frame = snapshot.frame\n",
    "            ts = int(snapshot.timestamp.elapsed_seconds * 1e6)\n",
    "            \n",
    "#             ds.write_lidar(\"lidar\", ts, lidar_pcl)\n",
    "#             ds.write_image(\"camera\", ts,  compute_data_buffer(image_rgb))\n",
    "#             ds.write_image(\"semantic\", ts,  compute_data_buffer(image_seg))\n",
    "#             ds.write_gnss(\"gnss\", ts, gnss_data)\n",
    "            \n",
    "            cv2.imshow(\"img\", np_image2)\n",
    "            \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "            if ego_vehicle.get_location().y > 140:\n",
    "                break\n",
    "finally:\n",
    "    \n",
    "    actor_list += sensor_actor_list\n",
    "    \n",
    "    for actor in actor_list:\n",
    "        actor.destroy()\n",
    "    actor_list = []\n",
    "    cv2.destroyAllWindows()\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
